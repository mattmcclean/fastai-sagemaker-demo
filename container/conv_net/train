#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import json
import os
import glob
import shutil

from fastai.imports import *

from fastai.transforms import *
from fastai.conv_learner import *
from fastai.model import *
from fastai.dataset import *
from fastai.sgdr import *


# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
model_path = os.path.join(prefix, 'model')
output_path = os.path.join(prefix, 'output')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
train_channel_name='training'
training_path = os.path.join(input_path, train_channel_name)

valid_channel_name='validation'
valid_path = os.path.join(input_path, valid_channel_name)

def get_relative_path(filename):
    s1 = os.path.split(filename)
    p = os.path.split(s1[0])[1]
    return os.path.join(p, s1[1])

def create_dummy_data(src_path, dest_root, sub_dir, num_items=2):
    if not os.path.isdir(dest_root): os.mkdir(dest_root)
    dst_path = os.path.join(dest_root, sub_dir)
    classes = os.listdir(src_path)
    for d in classes:
        if d.startswith('.'): continue
        if not os.path.isdir(dst_path): os.mkdir(dst_path)
        if not os.path.isdir(os.path.join(dst_path, d)): os.mkdir(os.path.join(dst_path, d))
        fnames = glob('{}/{}/*.jpg'.format(src_path, d))
        for i in range(num_items):
            shutil.copyfile(fnames[i], os.path.join(dst_path, get_relative_path(fnames[i])))

# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)

        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, train_channel_name))

        # Here we only support 3 hyperparameters. Learning rate, image size and epochs
        learning_rate = float(trainingParams.get('learning_rate', 0.01))
        epochs = int(trainingParams.get('epochs', 3))
        image_size = int(trainingParams.get('image_size', 224))
        print("Hyperparameters 'learning_rate' is {}, 'epochs' is {}, 'image_size' is {}".format(learning_rate, epochs, image_size))

        # Now use fastai library to train the model.
        arch=resnet34
        tfms = tfms_from_model(arch, image_size, aug_tfms=transforms_side_on, max_zoom=1.1)
        data = ImageClassifierData.from_paths(prefix, tfms=tfms,trn_name=training_path, val_name=valid_path)
        print('Label for validation data: {}'.format(data.val_y))
        print('Classes from data is: {}'.format(data.classes))

        learn = ConvLearner.pretrained(arch, data, precompute=True, models_name='model')
        print("Training one epoch with precomputation to initialize last layers")
        learn.fit(learning_rate, 2)
        learn.precompute=False
#        learn.fit(learning_rate, 1)
#        learn.precompute=False
#        print("Training with conv layers frozen and no precompute")
#        learn.fit(learning_rate, epochs, cycle_len=1)
#        learn.unfreeze()
#        print("Training with conv layers unfrozen and multiple cycles")
#        lr=np.array([learning_rate/100,learning_rate/10,learning_rate])
#        learn.fit(lr, epochs, cycle_len=1, cycle_mult=2)

        # save the model
        print("Saving model")
        learn.save('conv_net_model')

        print("Saving some example images")
        create_dummy_data(training_path, os.path.join(model_path, "data"), "train")
        create_dummy_data(valid_path, os.path.join(model_path, "data"), "valid")

        print('Training complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
